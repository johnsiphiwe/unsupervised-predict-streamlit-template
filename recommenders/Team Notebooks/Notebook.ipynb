{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3e2493",
   "metadata": {},
   "source": [
    "# Team 10 - Unsupervised Learning Predict\n",
    "\n",
    "Â© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "\n",
    "## Team Members\n",
    "\n",
    " - Mulalo Malange\n",
    " - Rebecca Kekana\n",
    " - Thandiwe Khalaki\n",
    " - Njabulo Nyembe\n",
    " - John Siphiwe Seelamo\n",
    "\n",
    "\n",
    "## Introduction: Movie Recommendation Challenge\n",
    "\n",
    "![](https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/best-movies-1614634680.jpg?crop=1.00xw:1.00xh;0,0&resize=980:*)\n",
    "\n",
    "*Insert Intro\n",
    " \n",
    "\n",
    "## Predict Overview\n",
    "\n",
    "*Insert Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278827e",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Modeling</a>\n",
    "\n",
    "<a href=#five>5. Model Performance</a>\n",
    "\n",
    "<a href=#six>6. Model Explanations</a>\n",
    "\n",
    "<a href=#seven>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"WMEw3gZXczce1pWTOpKnPjwMo\",\n",
    "    project_name=\"movie-recommender\",\n",
    "    workspace=\"rebeccakekana\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00e32d",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "# 1. Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac80a5",
   "metadata": {},
   "source": [
    "In this section we import the necessary libraries needed for Data Analysis, Data Preprocessing, Data Visualization, Feature Engineering and Model Building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import SVD,accuracy\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ebda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cc7a2",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "# 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Load the Train and Test datasets, as well as other relevent datasets from the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb196bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\") \n",
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "tags_df = pd.read_csv(\"tags.csv\")\n",
    "links_df = pd.read_csv(\"links.csv\")\n",
    "\n",
    "genome_scores_df = pd.read_csv(\"genome_scores.csv\")\n",
    "genome_tags_df = pd.read_csv(\"genome_tags.csv\")\n",
    "imdb_data_df = pd.read_csv(\"imdb_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d178b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shapes = {'Train': df_train.shape,\n",
    "            'Test': df_test.shape,\n",
    "            'Movies': movies_df.shape,\n",
    "            'IMDB': imdb_data_df.shape,\n",
    "            'Links': links_df.shape,\n",
    "            'Tags': tags_df.shape,\n",
    "            'Genome scores': genome_scores_df.shape,\n",
    "            'Genome tags': genome_tags_df.shape,\n",
    "}\n",
    "\n",
    "df_shape = pd.DataFrame(list(df_shapes.items()), columns=['Data Set', 'Shape'])\n",
    "df_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e98e68",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "# 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Exploratory Data Analysis refers to the critical process of performing initial investigations on a dataset in order to discover patterns in the data, spot anomalies, to check assumptions with the help of some statistics and graphical representations. The following section analyses and provides an overview of the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2119855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show full value of dataframe\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show full value of dataframe\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# Display the first 5 entries in each dataframe \n",
    "display(df_train.head())\n",
    "display(df_test.head())\n",
    "display(movies_df.head())\n",
    "display(imdb_data_df.head())\n",
    "display(links_df.head())\n",
    "display(tags_df.head())\n",
    "display(genome_scores_df.head())\n",
    "display(genome_tags_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9139f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['year'] = movies_df['title'].str.extract(\"\\((.*)\\)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['title'] = movies_df['title'].apply(lambda x: x[:-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07702cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_df['relevance'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dee1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_df['relevance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object data types to strings for string handling\n",
    "def change_data_types(data):\n",
    "    for i in data.columns:\n",
    "        if data[i].dtypes == \"O\":\n",
    "            data[i] = data[i].astype(str)\n",
    "    return data           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ade14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train =change_data_types(df_train)\n",
    "df_test = change_data_types(df_test)\n",
    "movies_df = change_data_types(movies_df)\n",
    "imdb_data_df = change_data_types(imdb_data_df)\n",
    "links_df = change_data_types(links_df)\n",
    "tags_df = change_data_types(tags_df)\n",
    "genome_scores_df = change_data_types(genome_scores_df)\n",
    "genome_tags_df = change_data_types(genome_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25600aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessor\n",
    "def clean_data(df, column):\n",
    "    \n",
    "    # Turn all words to lowercase\n",
    "    df[column] = df[column].str.lower()\n",
    "\n",
    "    # Discarding the pipes between words\n",
    "    df[column] = df[column].map(lambda x: x.split('|'))\n",
    "    df[column] = df[column].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_names(df, column):\n",
    "    # Discarding the pipes between the full names and getting only the first ten names\n",
    "    df[column] = df[column].map(lambda x: x.split('|')[:11])   \n",
    "    \n",
    "    # Removing spaces between names\n",
    "    df[column] = df[column].apply(lambda x: \"\".join(x.lower() for x in x.split()))\n",
    "    df[column] = df[column].apply(lambda x: \"\".join(x.lower() for x in x.split()))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = clean_data(movies_df, 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of movies by genre\n",
    "genre = movies_df['genres'].value_counts()\n",
    "\n",
    "# Create a word cloud with max 100 \n",
    "print(\"Movie Genre Frequency\")\n",
    "wordcloud = WordCloud(max_words=100, background_color='black', height=2000, width=4000).generate_from_frequencies(genre)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which genre do most released movies fall under? We don't have a clear indictation of how these movie genres are rated yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(df_train, movies_df, on='movieId', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d67bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average rating per movie\n",
    "movies.groupby(by='title')['rating'].mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53281519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ratings per movie\n",
    "movies.groupby(by='title')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5395ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.groupby(by='title')['rating'].count().sort_values(ascending=False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summ = pd.DataFrame(movies.groupby(by='title')['rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summ['No. of people Rated'] = movies.groupby(by='title')['rating'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc05d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summ.sort_values(by=['rating'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summ.sort_values(by=['No. of people Rated'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=movies_summ['rating'],y=movies_summ['No. of people Rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb302280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots for years\n",
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.countplot(y = movies['year'], data = movies, order = movies['year'].value_counts().index[0:10] )\n",
    "\n",
    "#add title\n",
    "ax.set_title(\"Top 10 Years with Highest Number of Movies Released\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize overall rating by users\n",
    "movies['rating'].value_counts().plot(kind='bar',alpha=0.7,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1b67d",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "# 4. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f0cdd",
   "metadata": {},
   "source": [
    "## 4.1 Content Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff71fe2",
   "metadata": {},
   "source": [
    "Recommendation systems are a collection of algorithms used to recommend items to users based on information taken from the user. These systems have become ubiquitous, and can be commonly seen in online stores, movies databases and job finders. In this notebook, we will explore Content-based recommendation systems and implement a simple version of one using Python and the Pandas library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0877caa",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6536e8",
   "metadata": {},
   "source": [
    "First, let's get all of the imports out of the way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3613fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe manipulation library\n",
    "import pandas as pd\n",
    "#Math functions, we'll only need the sqrt function so let's import only that\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25969b81",
   "metadata": {},
   "source": [
    "Now let's read each file into their Dataframes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2535c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"train.csv\")\n",
    "movies_df = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4511cc6",
   "metadata": {},
   "source": [
    "Let's also remove the year from the **title** column by using pandas' replace function and store in a new **year** column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using regular expressions to find a year stored between parentheses\n",
    "#We specify the parantheses so we don't conflict with movies that have years in their titles\n",
    "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
    "#Removing the parentheses\n",
    "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
    "#Removing the years from the 'title' column\n",
    "movies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n",
    "#Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
    "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94c02d",
   "metadata": {},
   "source": [
    "With that, let's also split the values in the **Genres** column into a **list of Genres** to simplify for future use. This can be achieved by applying Python's split string function on the correct column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every genre is separated by a | so we simply have to call the split function on |\n",
    "movies_df['genres'] = movies_df.genres.str.split('|')\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30214021",
   "metadata": {},
   "source": [
    "Since keeping genres in a list format isn't optimal for the content-based recommendation system technique, we will use the One Hot Encoding technique to convert the list of genres to a vector where each column corresponds to one possible value of the feature. This encoding is needed for feeding categorical data. In this case, we store every different genre in columns that contain either 1 or 0. 1 shows that a movie has that genre and 0 shows that it doesn't. Let's also store this dataframe in another variable since genres won't be important for our first recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.\n",
    "moviesWithGenres_df = movies_df.copy()\n",
    "\n",
    "#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column\n",
    "for index, row in movies_df.iterrows():\n",
    "    for genre in row['genres']:\n",
    "        moviesWithGenres_df.at[index, genre] = 1\n",
    "#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\n",
    "moviesWithGenres_df = moviesWithGenres_df.fillna(0)\n",
    "moviesWithGenres_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470abe3",
   "metadata": {},
   "source": [
    "Next, let's look at the ratings dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fae84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a474b",
   "metadata": {},
   "source": [
    "Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the timestamp column, so let's drop it to save memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61690b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop removes a specified row or column from a dataframe\n",
    "ratings_df = ratings_df.drop('timestamp', 1)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5c8ab",
   "metadata": {},
   "source": [
    "### Content-Based recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04527de",
   "metadata": {},
   "source": [
    "Now, let's take a look at how to implement **Content-Based** or **Item-Item recommendation systems**. This technique attempts to figure out what a user's favourite aspects of an item is, and then recommends items that present those aspects. In our case, we're going to try to figure out the input's favorite genres from the movies and ratings given.\n",
    "\n",
    "Let's begin by creating an input user to recommend movies to:\n",
    "\n",
    "Notice: To add more movies, simply increase the amount of elements in the **userInput**. Feel free to add more in! Just be sure to write it in with capital letters and if a movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The' .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af842d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "userInput = [\n",
    "            {'title':'Breakfast Club, The', 'rating':5},\n",
    "            {'title':'Toy Story', 'rating':3.5},\n",
    "            {'title':'Jumanji', 'rating':2},\n",
    "            {'title':\"Pulp Fiction\", 'rating':5},\n",
    "            {'title':'Akira', 'rating':4.5}\n",
    "         ] \n",
    "inputMovies = pd.DataFrame(userInput)\n",
    "inputMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffdc2f",
   "metadata": {},
   "source": [
    "#### Add movieId to input user\n",
    "\n",
    "With the input complete, let's extract the input movie's ID's from the movies dataframe and add them into it.\n",
    "\n",
    "We can achieve this by first filtering out the rows that contain the input movie's title and then merging this subset with the input dataframe. We also drop unnecessary columns for the input to save memory space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the movies by title\n",
    "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
    "#Then merging it so we can get the movieId. It's implicitly merging it by title.\n",
    "inputMovies = pd.merge(inputId, inputMovies)\n",
    "#Dropping information we won't use from the input dataframe\n",
    "inputMovies = inputMovies.drop('genres', 1).drop('year', 1)\n",
    "#Final input dataframe\n",
    "#If a movie you added in above isn't here, then it might not be in the original \n",
    "#dataframe or it might spelled differently, please check capitalisation.\n",
    "inputMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90eda7",
   "metadata": {},
   "source": [
    "We're going to start by learning the input's preferences, so let's get the subset of movies that the input has watched from the Dataframe containing genres defined with binary values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the movies from the input\n",
    "userMovies = moviesWithGenres_df[moviesWithGenres_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
    "userMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f08e5b",
   "metadata": {},
   "source": [
    "We'll only need the actual genre table, so let's clean this up a bit by resetting the index and dropping the movieId, title, genres and year columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index to avoid future issues\n",
    "userMovies = userMovies.reset_index(drop=True)\n",
    "#Dropping unnecessary issues due to save memory and to avoid issues\n",
    "userGenreTable = userMovies.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\n",
    "userGenreTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bafc2a",
   "metadata": {},
   "source": [
    "Now we're ready to start learning the input's preferences!\n",
    "\n",
    "To do this, we're going to turn each genre into weights. We can do this by using the input's reviews and multiplying them into the input's genre table and then summing up the resulting table by column. This operation is actually a dot product between a matrix and a vector, so we can simply accomplish by calling the Pandas \"dot\" function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44706ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputMovies['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot produt to get weights\n",
    "userProfile = userGenreTable.transpose().dot(inputMovies['rating'])\n",
    "#The user profile\n",
    "userProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6cf99",
   "metadata": {},
   "source": [
    "Now, we have the weights for every of the user's preferences. This is known as the User Profile. Using this, we can recommend movies that satisfy the user's preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96938934",
   "metadata": {},
   "source": [
    "Let's start by extracting the genre table from the original dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's get the genres of every movie in our original dataframe\n",
    "genreTable = moviesWithGenres_df.set_index(moviesWithGenres_df['movieId'])\n",
    "#And drop the unnecessary information\n",
    "genreTable = genreTable.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\n",
    "genreTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "genreTable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiply the genres by the weights and then take the weighted average\n",
    "recommendationTable_df = ((genreTable*userProfile).sum(axis=1))/(userProfile.sum())\n",
    "recommendationTable_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort our recommendations in descending order\n",
    "recommendationTable_df = recommendationTable_df.sort_values(ascending=False)\n",
    "#Just a peek at the values\n",
    "recommendationTable_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc3b4c",
   "metadata": {},
   "source": [
    "Now here's the recommendation table!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final recommendation table\n",
    "movies_df.loc[movies_df['movieId'].isin(recommendationTable_df.head(20).keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7d326",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Content-Based Filtering\n",
    "\n",
    "##### Advantages\n",
    "\n",
    "*   Learns user's preferences\n",
    "*   Highly personalized for the user\n",
    "\n",
    "##### Disadvantages\n",
    "\n",
    "*   Doesn't take into account what others think of the item, so low quality item recommendations might happen\n",
    "*   Extracting data is not always intuitive\n",
    "*   Determining what characteristics of the item the user dislikes or likes is not always obvious\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade859af",
   "metadata": {},
   "source": [
    "## 4.2 Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba9ab9",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872ed84",
   "metadata": {},
   "source": [
    "First, let's get all of the imports out of the way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da24634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe manipulation library\n",
    "import pandas as pd\n",
    "#Math functions, we'll only need the sqrt function so let's import only that\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ef799",
   "metadata": {},
   "source": [
    "Now let's read each file into their Dataframes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bda135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the movie information into a pandas dataframe\n",
    "movies_df = pd.read_csv('movies.csv')\n",
    "#Storing the user information into a pandas dataframe\n",
    "ratings_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058fd6ca",
   "metadata": {},
   "source": [
    "Let's also take a peek at how each of them are organized:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Head is a function that gets the first N rows of a dataframe. N's default is 5.\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b79f87",
   "metadata": {},
   "source": [
    "So each movie has a unique ID, a title with its release year along with it (Which may contain unicode characters) and several different genres in the same field. Let's remove the year from the title column and place it into its own one by using the handy [extract](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.extract.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01#pandas.Series.str.extract) function that Pandas has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using regular expressions to find a year stored between parentheses\n",
    "#We specify the parantheses so we don't conflict with movies that have years in their titles\n",
    "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
    "#Removing the parentheses\n",
    "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
    "#Removing the years from the 'title' column\n",
    "movies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n",
    "#Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
    "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the result!\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6096aa",
   "metadata": {},
   "source": [
    "With that, let's also drop the genres column since we won't need it for this particular recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c89b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the genres column\n",
    "movies_df = movies_df.drop('genres', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the final movies dataframe:\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac347ef2",
   "metadata": {},
   "source": [
    "Next, let's look at the ratings dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebdfae",
   "metadata": {},
   "source": [
    "Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the timestamp column, so let's drop it to save on memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop removes a specified row or column from a dataframe\n",
    "ratings_df = ratings_df.drop('timestamp', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62fc21",
   "metadata": {},
   "source": [
    "Here's how the final ratings Dataframe looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563e518",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f8a93",
   "metadata": {},
   "source": [
    "Now it's time to start our work on recommendation systems.\n",
    "\n",
    "The first technique we're going to take a look at is called **Collaborative Filtering**, which is also known as **User-User Filtering**. As hinted by its alternate name, this technique uses other users to recommend items to the input user. It attempts to find users that have similar preferences and opinions as the input and then recommends items that they have liked to the input. There are several methods of finding similar users (Even some making use of Machine Learning), and the one we will be using here is going to be based on the **Pearson Correlation Function**.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/images/User_Item.png\" width=800px>\n",
    "\n",
    "The process for creating a User Based recommendation system is as follows:\n",
    "\n",
    "*   Select a user with the movies the user has watched\n",
    "*   Based on his rating of the movies, find the top X neighbours\n",
    "*   Get the watched movie record of the user for each neighbour\n",
    "*   Calculate a similarity score using some formula\n",
    "*   Recommend the items with the highest score\n",
    "\n",
    "Let's begin by creating an input user to recommend movies to:\n",
    "\n",
    "Notice: To add more movies, simply increase the amount of elements in the userInput. Feel free to add more in! Just be sure to write it in with capital letters and if a movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The' .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "userInput = [\n",
    "            {'title':'Breakfast Club, The', 'rating':5},\n",
    "            {'title':'Toy Story', 'rating':3.5},\n",
    "            {'title':'Jumanji', 'rating':2},\n",
    "            {'title':\"Pulp Fiction\", 'rating':5},\n",
    "            {'title':'Akira', 'rating':4.5}\n",
    "         ] \n",
    "inputMovies = pd.DataFrame(userInput)\n",
    "inputMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94393ffb",
   "metadata": {},
   "source": [
    "#### Add movieId to input user\n",
    "\n",
    "With the input complete, let's extract the input movies's ID's from the movies dataframe and add them into it.\n",
    "\n",
    "We can achieve this by first filtering out the rows that contain the input movies' title and then merging this subset with the input dataframe. We also drop unnecessary columns for the input to save memory space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the movies by title\n",
    "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
    "#Then merging it so we can get the movieId. It's implicitly merging it by title.\n",
    "inputMovies = pd.merge(inputId, inputMovies)\n",
    "#Dropping information we won't use from the input dataframe\n",
    "inputMovies = inputMovies.drop('year', 1)\n",
    "#Final input dataframe\n",
    "#If a movie you added in above isn't here, then it might not be in the original \n",
    "#dataframe or it might spelled differently, please check capitalisation.\n",
    "inputMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753be9c6",
   "metadata": {},
   "source": [
    "#### The users who has seen the same movies\n",
    "\n",
    "Now with the movie ID's in our input, we can now get the subset of users that have watched and reviewed the movies in our input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out users that have watched movies that the input has watched and storing it\n",
    "userSubset = ratings_df[ratings_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
    "userSubset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0620e4",
   "metadata": {},
   "source": [
    "We now group up the rows by user ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ee29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\n",
    "userSubsetGroup = userSubset.groupby(['userId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0e680",
   "metadata": {},
   "source": [
    "Let's look at one of the users, e.g. the one with userID=1680.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetGroup.get_group(1680)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14feb041",
   "metadata": {},
   "source": [
    "Let's also sort these groups so the users that share the most movies in common with the input have higher priority. This provides a richer recommendation since we won't go through every single user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting it so users with movie most in common with the input will have priority\n",
    "userSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47123835",
   "metadata": {},
   "source": [
    "Now let's look at the first user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9669ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetGroup[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5504e563",
   "metadata": {},
   "source": [
    "#### Similarity of users to input user\n",
    "\n",
    "Next, we are going to compare all users (not really all !!!) to our specified user and find the one that is most similar.\\\n",
    "We're going to find out how similar each user is to the input through the **Pearson Correlation Coefficient**. It is used to measure the strength of a linear association between the two variables. The formula for finding this coefficient between sets X and Y with N values can be seen in the image below.\n",
    "\n",
    "Why Pearson Correlation?\n",
    "\n",
    "Pearson correlation is invariant to scaling, i.e. multiplying all elements by a nonzero constant or adding any constant to all elements. For example, if you have two vectors X and Y, then, pearson(X, Y) == pearson(X, 2 \\* Y + 3). This is a pretty important property in recommendation systems because, for example, two users might rate two series of items totally differently in terms of absolute rates, but they would be similar users (i.e. with similar ideas) with similar rates in various scales .\n",
    "\n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd1ccc2979b0fd1c1aec96e386f686ae874f9ec0 \"Pearson Correlation\")\n",
    "\n",
    "The values given by the formula vary from r = -1 to r = 1, where 1 forms a direct correlation between the two entities (it means a perfect positive correlation) and -1 forms a perfect negative correlation.\n",
    "\n",
    "In our case, a 1 means that the two users have similar tastes while a -1 means the opposite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50435a6",
   "metadata": {},
   "source": [
    "We will select a subset of users to iterate through. This limit is imposed because we don't want to waste too much time going through every single user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81146e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetGroup = userSubsetGroup[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab6833",
   "metadata": {},
   "source": [
    "Now, we calculate the Pearson Correlation between input user and subset group, and store it in a dictionary, where the key is the user Id and the value is the coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f410ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\n",
    "pearsonCorrelationDict = {}\n",
    "\n",
    "#For every user group in our subset\n",
    "for name, group in userSubsetGroup:\n",
    "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "    group = group.sort_values(by='movieId')\n",
    "    inputMovies = inputMovies.sort_values(by='movieId')\n",
    "    #Get the N for the formula\n",
    "    nRatings = len(group)\n",
    "    #Get the review scores for the movies that they both have in common\n",
    "    temp_df = inputMovies[inputMovies['movieId'].isin(group['movieId'].tolist())]\n",
    "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
    "    tempRatingList = temp_df['rating'].tolist()\n",
    "    #Let's also put the current user group reviews in a list format\n",
    "    tempGroupList = group['rating'].tolist()\n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y\n",
    "    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n",
    "    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n",
    "    \n",
    "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
    "    else:\n",
    "        pearsonCorrelationDict[name] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonCorrelationDict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23413440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
    "pearsonDF.columns = ['similarityIndex']\n",
    "pearsonDF['userId'] = pearsonDF.index\n",
    "pearsonDF.index = range(len(pearsonDF))\n",
    "pearsonDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea99162",
   "metadata": {},
   "source": [
    "#### The top x similar users to input user\n",
    "\n",
    "Now let's get the top 50 users that are most similar to the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "topUsers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2fd3e",
   "metadata": {},
   "source": [
    "Now, let's start recommending movies to the input user.\n",
    "\n",
    "#### Rating of selected users to all movies\n",
    "\n",
    "We're going to do this by taking the weighted average of the ratings of the movies using the Pearson Correlation as the weight. But to do this, we first need to get the movies watched by the users in our **pearsonDF** from the ratings dataframe and then store their correlation in a new column called \\_similarityIndex\". This is achieved below by merging of these two tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\n",
    "topUsersRating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446dc03d",
   "metadata": {},
   "source": [
    "Now all we need to do is simply multiply the movie rating by its weight (the similarity index), then sum up the new ratings and divide it by the sum of the weights.\n",
    "\n",
    "We can easily do this by simply multiplying two columns, then grouping up the dataframe by movieId and then dividing two columns:\n",
    "\n",
    "It shows the idea of all similar users to candidate movies for the input user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ccf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiplies the similarity by the user's ratings\n",
    "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\n",
    "topUsersRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applies a sum to the topUsers after grouping it up by userId\n",
    "tempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\n",
    "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
    "tempTopUsersRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an empty dataframe\n",
    "recommendation_df = pd.DataFrame()\n",
    "#Now we take the weighted average\n",
    "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
    "recommendation_df['movieId'] = tempTopUsersRating.index\n",
    "recommendation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526e95b",
   "metadata": {},
   "source": [
    "Now let's sort it and see the top 20 movies that the algorithm recommended!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ea9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
    "recommendation_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4580f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.loc[movies_df['movieId'].isin(recommendation_df.head(10)['movieId'].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db4409",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Collaborative Filtering\n",
    "\n",
    "##### Advantages\n",
    "\n",
    "*   Takes other user's ratings into consideration\n",
    "*   Doesn't need to study or extract information from the recommended item\n",
    "*   Adapts to the user's interests which might change over time\n",
    "\n",
    "##### Disadvantages\n",
    "\n",
    "*   Approximation function can be slow\n",
    "*   There might be a low amount of users to approximate\n",
    "*   Privacy issues when trying to learn the user's preferences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f77e8",
   "metadata": {},
   "source": [
    "## 4.3 SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd863b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], Reader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd=SVD(n_epochs = 30, n_factors = 200, init_std_dev = 0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8248015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "svd.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_pred= svd.test(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model performance\n",
    "rsme_collabo = accuracy.rmse(test_pred,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e75b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85059d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the rating for each user and movie\n",
    "ratings=[]\n",
    "for x,y in test.itertuples(index=False):\n",
    "    output=svd.predict(x,y)\n",
    "    ratings.append(output)\n",
    "    \n",
    "output_df=pd.DataFrame(ratings)[['uid','iid','est']]\n",
    "output_df['ID']=output_df['uid'].astype(str) + '_' + output_df['iid'].astype(str)\n",
    "output_df=output_df[['ID','est']]\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf14f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the \"results\" dataframe and convert to csv\n",
    "results = pd.DataFrame({\"Id\":output_df['ID'],\"rating\": output_df['est']})\n",
    "results.to_csv(\"SVD.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team_10_submission = pd.DataFrame({'id': results.Id, 'rating': results.rating})\n",
    "Team_10_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0d609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
